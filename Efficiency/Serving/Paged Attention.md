* Во время инференса ллм встает задача аллокации KV-кэша. Мы не можем знать, какой размер нам понадобится, поэтому в качестве наивного решения KV-кэш преаллоцируется заранее по заданному размеру, обычно в качестве размера выступает параметр max_tokens в запросе на генерацию. Это решение очень неэффективно использует память, давайте попытаемся эту проблему побороть. 
* Если стадия префилла (вычисления эмбеддингов и kv-значений для промпта) это compute-bound задача в силу того, что она хорошо батчуется, то стадия декодинга -- это уже memory bound, и на ней хочется макимально увеличить батч, что требует больше свободной памяти
Неэффективности в хранении KV-кэша можно поделить на две группы:
* External fragmentation -- фрагментация, свазанная с выравниванием аллоцируемой памяти на уровне аллкоатора GPU
* Internal fragmentation -- фрагментация, связанная с неиспользуемой преалоцированной памятью для KV-кэша
Суть в том, чтобы смотреть на память под KV-кэш также, как это делает операционная система: создать механизм виртуальной памяти и страниц. Разобьем кэш на блоки размера $B$, каждый блок будет хранить предпосчитанные K и V значения для заданной последовательности. Во время префилла просим у аллокатора нужное количество блоков и записываем туда наши кэши. Во время декодинга спрашиваем у аллокатора, в какой блок можно записать кэши для нового токена, а на уровне кернела делаем трансляцию "физического адреса" в "виртуальный". Таким образом, мы решаем проблему фрагментации памяти. 