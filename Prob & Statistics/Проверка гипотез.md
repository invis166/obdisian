Можно выделить два основных шага в процессе проверки гипотезы:
1. Формулируем гипотезу. Хотим проверить информацию о некотором параметре распределения наших данных $\theta$. Формируется нулевая гипотеза $H_0 (\theta=\theta_0)$ и альтернативная гипотеза $H_1(\theta \ne \theta_0)$.
2. Проверяем гипотезу. Обычно проверка гипотезы выглядит следующим образом: мы строим некоторый rejection region $R$ и смотрим, входит ли значение некоторой статистики $T(X_n)$ в этот регион. Если входит, то отвергаем $H_0$ (можно сказать, что $\theta \ne \theta_0$ статистически значимо). Иначе -- нет достаточных сведений для отвержения $H_0$

Мы хотим иметь некоторые вероятностные гарантии на такой процесс проверки. Больше всего нас интересуют следующие характеристики теста:
1. **Уровень значимости (ошибка первого рода)**. $\alpha = \mathbb{P}(\text{reject } H_0 | H_0 \text{ is true})$ -- вероятность отвергнуть верную нулевую гипотезу. Если у теста низкий уровень значимости, то при условии отсутствия эффекта тест будет часто говорить, что эффект есть.
2. **Мощность.** $1 - \beta = \mathbb{P}(\text{reject } H_0 | H_1 \text{ is true})$ -- вероятность обнаружить эффект при условии того, что он действительно есть. Если у теста низкая мощность, то в случае, если эффект есть, мы часто говорить, что его на самом деле нет.
3. **Ошибка второго рода**. $\beta = \mathbb{P}(\text{not reject } H_0 | H_1 \text{ is true})$ -- вероятность не обнаружить эффект при условии того, что он действительно есть

![[Type-1-vs-type-2-errors-with-pregnancy.png]]
