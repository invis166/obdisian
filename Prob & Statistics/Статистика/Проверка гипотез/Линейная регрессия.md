## Коэффициенты линейной регрессии
Как известно, коэффициенты линейной регрессии можно найти по формуле
$$\hat\beta = (X^tX)^{-1}X^ty$$
В предположении линейной регрессии $y = X\beta + \epsilon, \epsilon \sim \mathcal{N}(0, \sigma^2I)$
Тогда [_](obsidian://adv-uri?vault=General%20ML&filepath=%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F%20%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F%2F%D0%9F%D0%BE%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0%20%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B8.md&block=estimate-variance)
$$\hat\beta \sim \mathcal{N}(\beta, \sigma^2(X^tX)^{-1})$$

Таким образом, мы можем делать t-test для коэффициентов регрессии. Более того, если в предположении регрессии шум распределен отлично от нормального, коэффициенты все равно будут ассимпотически нормальны в силу ЦПТ.
### Частный случай. Один предиктор.
В случае лишь одного предиктора (и свободного члена, конечно), коэффициент перед ним будет равняться 

(Проверяется гипотеза о том, что корреляция равна нулю)



Можно строить доверительные интервалы для предсказаний и коэффициентов линейных моделей (круто блин) (см обобщенные линейные модели)
Можно проверять гипотезы линейной регрессией


### T-test