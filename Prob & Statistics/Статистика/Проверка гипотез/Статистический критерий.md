Можно выделить два основных шага в процессе проверки гипотезы:
1. Формулируем гипотезу. Хотим проверить информацию о некотором параметре распределения наших данных $\theta$. Формируется нулевая гипотеза $H_0 (\theta=\theta_0)$ и альтернативная гипотеза $H_1(\theta \ne \theta_0)$.
2. Проверяем гипотезу. Обычно проверка гипотезы выглядит следующим образом: мы строим некоторый rejection region $R$ и смотрим, входит ли значение некоторой статистики $T(X_n)$ в этот регион. Если входит, то отвергаем $H_0$ (можно сказать, что $\theta \ne \theta_0$ статистически значимо). Иначе -- нет достаточных сведений для отвержения $H_0$
*Статистический критерий* - это правило, по которому мы отвергаем или не отвергаем нулевую гипотезу. В стандартном случае обходятся видом ${T(X_n) \in R}$

Мы хотим иметь некоторые вероятностные гарантии на такой процесс проверки. Больше всего нас интересуют следующие характеристики теста:
1. **Уровень значимости (ошибка первого рода)**. $\alpha = \mathbb{P}_{H_0}(\text{reject } H_0)$ -- вероятность отвергнуть верную нулевую гипотезу. Если у теста низкий уровень значимости, то при условии отсутствия эффекта тест будет часто говорить, что эффект есть.
2. **Мощность.** $1 - \beta = \mathbb{P}_{H_1}(\text{reject } H_0)$ -- вероятность обнаружить эффект при условии того, что он действительно есть. Если у теста низкая мощность, то в случае, если эффект есть, мы часто говорить, что его на самом деле нет. (Примечание: на самом деле вероятность при $H_1$ не совсем понятно определена, потому что $H_1$ это целое множество параметров. По этой причине в определении следует брать супремум)
3. **Ошибка второго рода**. $\beta = \mathbb{P}_{H_1}(\text{not reject } H_0)$ -- вероятность не обнаружить эффект при условии того, что он действительно есть

![[Type-1-vs-type-2-errors-with-pregnancy.png]]

Интерпретация у этих параметров следующая: если проводить АБ тест много-много раз, то при условии истинности $H_0$ мы будем отвергать (результат будет статзначим) ее в $\alpha$ доле тестов. В обратном случае, когда истина $H_1$, мы не будем отвергать $H_0$ (получить нестатзначимый результат) в $\beta$ доле тестов.

На самом деле, не очень корректно писать вероятности по типу $\mathbb{P}(*|H_0 \text{ is true})$ или $\mathbb{P}(*|H_1\text{ is true})$, потому что в действительности $H_0$ или $H_1$ либо верны, либо не верны -- это не случайные события (здесь можно вспомнить аналогичную неточность, когда мы говорим про вероятность того, что оцениваемый параметр лежит в какой-либо реализации [[Доверительные интервалы|доверительного интервала]]) 