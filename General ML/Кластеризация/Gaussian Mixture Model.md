Идея в том, чтобы ввести латентные переменные и воспользоваться [[EM|EM-алгоритмом]].
Предположение: пусть имеется $k$ гауссиан с разными параметрами (среднее и дисперсия), и данные сгенерированы из смеси гауссиан:
$$
p(x|\theta) = \sum_{i=1}^k \pi_i \mathcal{N}(x|\mu_i, \Sigma_i)
$$
Теперь, давайте введем латентные переменные. Скажем, что у каждого объекта есть номер гауссианы, из которой он был сгенерирован:
$$
\begin{aligned}
p(x|z_k=1) &= \mathcal{N}(x|\mu_i, \Sigma_i) \\
q(z) &\sim Categorial(\pi_1, ..., \pi_k)
\end{aligned}
$$
Тогда совместное распределение:
$$
p(X, Z | \theta) = \prod_{i=1}^n p(x_i, z_i | \theta) = \prod_{i=1}^n\pi_{z_i}\mathcal{N}(x_i | \mu_{z_i}, \Sigma_{z_i})
$$
Теперь, чтобы воспользоваться [[EM|EM-алгоритмом]], нужно посчитать условное распределение на латентные переменные:
$$
p(z_i|x_i, \theta) = \frac{p(x_i, z_i|\theta)}{p(x)} = \frac{\pi_{z_i}\mathcal{N}(x|\mu_{z_i}, \Sigma_{z_i})}{\sum_{j=1}^k \pi_{z_j}\mathcal{N}(x | \mu_{z_j}, \Sigma_{z_j})}
$$
Для M-шага нужно оптимизировать этот функционал по $\theta$, т.е. по $\{\mu_1,...,\mu_k, \Sigma_1, ..., \Sigma_k, \pi_1, ..., \pi_k \}$. Вычислить максимум можно стандартными методами, не будут приводить здесь все формулы (может потом когда-то перепишу).
Итого, для каждой точки нашего распределения мы выдаем целое распределение на то, к каким кластерам она может относиться.